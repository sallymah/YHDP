package tw.com.hyweb.svc.yhdp.batch.framework.cursorThread;

import java.sql.Connection;
import java.util.HashMap;
import java.util.Iterator;
import java.util.Map;
import java.util.concurrent.ThreadPoolExecutor;

import org.apache.log4j.Logger;

import tw.com.hyweb.core.cp.batch.framework.Layer1Constants;
import tw.com.hyweb.core.cp.batch.framework.generic.BatchHandleResult;
import tw.com.hyweb.core.cp.batch.framework.generic.BatchHandler;
import tw.com.hyweb.core.cp.batch.framework.generic.BatchJob;
import tw.com.hyweb.service.db.info.TbBatchResultInfo;

public class BatchThreadJobHandler implements BatchHandler{

	private static final Logger LOGGER = Logger.getLogger(BatchThreadJobHandler.class);

    private final BatchJobFactory factory;
    private ThreadPoolJobExecutor threadPoolJobExecutor = null;
    private JobRunnerFactory jobRunnerFactory = null;
    private int waitThreadSecLimit = 0;
    private int waitThreadSleep = 1000;
    private int fetchCount = 10000;

    private HashMap<String,String> resultMap = new HashMap<String,String>();

    public BatchThreadJobHandler(BatchJobFactory factory, JobRunnerFactory jobRunnerFactory, ThreadPoolJobExecutor threadPoolJobExecutor)
    {
        this.factory = factory;
        this.jobRunnerFactory = jobRunnerFactory;
        this.threadPoolJobExecutor = threadPoolJobExecutor;
    }
	
    /**
     * �C���B�z�@��batch unit�A�B�z���|�I�sremark success�A���ѫh����rollback�éI�sremark failure
     * 
     * @see tw.com.hyweb.core.cp.batch.framework.generic.BatchHandler#handle(java.sql.Connection,
     *      java.lang.String)
     */
    public BatchHandleResult handle(Connection connection, String batchDate, TbBatchResultInfo tbBatchResultInfo) throws Exception
    {
        String rcode = Layer1Constants.RCODE_0000_OK;

        String successFailureCount = "";

        try
        {
        	getThreadPoolJobExecutor().startThreadPoolJob();

        	//資料總數分批動作
        	factory.divideBatch(connection, batchDate, fetchCount, tbBatchResultInfo);
        	
        	//資料分批撈取
        	while (factory.hasBatchNext()){
        		factory.init(connection, batchDate, tbBatchResultInfo);

                while (factory.hasNext())
                {
                    BatchJob job = factory.next(connection, batchDate);

                    if(getThreadPoolJobExecutor() != null && getThreadPoolJobExecutor().getExecutor() != null)
    		        {
    					if ( resultMap != null){
    		                ThreadPoolExecutor threadPoolExecutor = getThreadPoolJobExecutor().getExecutor();
    		                
    		                resultMap.put(job.toString(), Layer1Constants.WORKFLAG_INWORK);
    		                
    		                Runnable jobRunnerExecute = jobRunnerFactory.create(job, resultMap, batchDate);
    		                
    		                threadPoolExecutor.execute(jobRunnerExecute);
    					}
    	            
    		        }
                }
                
                while (getThreadPoolJobExecutor().getExecutor().getActiveCount() != 0) {
    	    		Thread.sleep(2000);
    	    		LOGGER.debug("ActiveCount:"+getThreadPoolJobExecutor().getExecutor().getActiveCount()
    	    				+" CompletedCount:"+getThreadPoolJobExecutor().getExecutor().getCompletedTaskCount());
    			}

                connection.commit();
        	}
        	
        	successFailureCount = checkInctlResult(resultMap);
        }
        finally
        {
            try
            {
                factory.destroy();
            }
            catch (Exception e)
            {
                LOGGER.warn("exception when destroy factory", e);
            }
            
            finally
            {
    	    	if(getThreadPoolJobExecutor() != null && getThreadPoolJobExecutor().getExecutor() != null 
    	                && getThreadPoolJobExecutor().getExecutor().isShutdown() == false)
    	        {
    				getThreadPoolJobExecutor().getExecutor().shutdown();
    				LOGGER.info("threadPoolJobExecutor shutdown!!");
    	        }
    	    	LOGGER.debug("========================================end===========================================");
            }
        }

        return new BatchHandleResult(successFailureCount, rcode);
    }
    
    public String checkInctlResult(HashMap<String,String> reportResultMap)
    {
        int okCnt = 0;
        int failCnt = 0;
        int notWorkingCnt = 0;
        int calWaitSec = 0;
        
        try
        {
            Thread.sleep(2000);
        }
        catch (InterruptedException e){}
        LOGGER.debug("wait thread job millis second limit:"+ waitThreadSecLimit+", sleep millis second:"+ waitThreadSleep);
        int fileSize = reportResultMap.size();
        while(fileSize > 0)
        {
            okCnt = 0;
            failCnt = 0;
            notWorkingCnt = 0;
            Iterator iter = reportResultMap.entrySet().iterator(); 
            while (iter.hasNext()) 
            { 
                Map.Entry entry = (Map.Entry) iter.next(); 
                String key = (String)entry.getKey(); 
                String val = (String)entry.getValue();
                switch (Integer.valueOf(val))
                {
                    case 1:
                        notWorkingCnt++;
                        break;
                    case 3:
                        okCnt++;
                        break;
                    case 9:
                        failCnt++;
                        break;
                    default:
                        notWorkingCnt++;
                        break;
                }   
            } 
            LOGGER.debug("Total inctl file size:"+fileSize + " fail count:"+failCnt + " ok count:"+okCnt + " not working count:"+notWorkingCnt);
            if((okCnt + failCnt) == fileSize)
            {
                /* �Ҧ��ɮפw���� */
            	LOGGER.debug("checkInctlResult: All work end. Total inctl file size:"+fileSize + " fail count:"+failCnt + " ok count:"+okCnt + " not working count:"+notWorkingCnt);
                break;
            }
            
            if(getThreadPoolJobExecutor() == null || getThreadPoolJobExecutor().getExecutor() == null)
            {
            	LOGGER.debug("checkInctlResult: getThreadPoolJobExecutor() == null || getThreadPoolJobExecutor().getExecutor() == null");
                break;
            }
            else if(getThreadPoolJobExecutor().getExecutor().isShutdown())
            {
            	LOGGER.debug("checkInctlResult: getThreadPoolJobExecutor().getExecutor().isShutdown()");
                break;
            }
            
            try
            {
                Thread.sleep(waitThreadSleep);
            }
            catch (InterruptedException e)
            {
                
            }
            
            if(waitThreadSecLimit > 0)
            {
                calWaitSec = calWaitSec + waitThreadSleep;
                if(waitThreadSecLimit < calWaitSec)
                {
                	LOGGER.debug("checkInctlResult: waitThreadSecLimit < calWaitSec");
                    break;
                }
            }
        }
        return "success:" + okCnt + ", failure:" + failCnt;
    }

	public ThreadPoolJobExecutor getThreadPoolJobExecutor() {
		return threadPoolJobExecutor;
	}

	public void setThreadPoolJobExecutor(ThreadPoolJobExecutor threadPoolJobExecutor) {
		this.threadPoolJobExecutor = threadPoolJobExecutor;
	}

	public JobRunnerFactory getJobRunnerFactory() {
		return jobRunnerFactory;
	}

	public void setJobRunnerFactory(JobRunnerFactory jobRunnerFactory) {
		this.jobRunnerFactory = jobRunnerFactory;
	}

	public int getFetchCount() {
		return fetchCount;
	}

	public void setFetchCount(int fetchCount) {
		this.fetchCount = fetchCount;
	}
}
